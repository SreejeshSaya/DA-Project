{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import  date\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%matplotlib inline\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "plt.style.use('ggplot')\n",
    "df=pd.read_csv('US_accidents_for_5_states.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Augmentation - Extracting time of Accident and splitting into different fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 993530 entries, 0 to 993529\n",
      "Data columns (total 56 columns):\n",
      " #   Column                 Non-Null Count   Dtype         \n",
      "---  ------                 --------------   -----         \n",
      " 0   Unnamed: 0             993530 non-null  int64         \n",
      " 1   ID                     993530 non-null  object        \n",
      " 2   Source                 993530 non-null  object        \n",
      " 3   TMC                    623281 non-null  float64       \n",
      " 4   Severity               993530 non-null  int64         \n",
      " 5   Start_Time             993530 non-null  datetime64[ns]\n",
      " 6   End_Time               993530 non-null  datetime64[ns]\n",
      " 7   Start_Lat              993530 non-null  float64       \n",
      " 8   Start_Lng              993530 non-null  float64       \n",
      " 9   End_Lat                370249 non-null  float64       \n",
      " 10  End_Lng                370249 non-null  float64       \n",
      " 11  Distance(mi)           993530 non-null  float64       \n",
      " 12  Description            993530 non-null  object        \n",
      " 13  Number                 244455 non-null  float64       \n",
      " 14  Street                 993530 non-null  object        \n",
      " 15  Side                   993530 non-null  object        \n",
      " 16  City                   993519 non-null  object        \n",
      " 17  County                 993530 non-null  object        \n",
      " 18  State                  993530 non-null  object        \n",
      " 19  Zipcode                993001 non-null  object        \n",
      " 20  Country                993530 non-null  object        \n",
      " 21  Timezone               993001 non-null  object        \n",
      " 22  Airport_Code           992980 non-null  object        \n",
      " 23  Weather_Timestamp      978749 non-null  object        \n",
      " 24  Temperature(F)         969922 non-null  float64       \n",
      " 25  Wind_Chill(F)          423274 non-null  float64       \n",
      " 26  Humidity(%)            968413 non-null  float64       \n",
      " 27  Pressure(in)           975350 non-null  float64       \n",
      " 28  Visibility(mi)         961501 non-null  float64       \n",
      " 29  Wind_Direction         970418 non-null  object        \n",
      " 30  Wind_Speed(mph)        829991 non-null  float64       \n",
      " 31  Precipitation(in)      410149 non-null  float64       \n",
      " 32  Weather_Condition      961656 non-null  object        \n",
      " 33  Amenity                993530 non-null  bool          \n",
      " 34  Bump                   993530 non-null  bool          \n",
      " 35  Crossing               993530 non-null  bool          \n",
      " 36  Give_Way               993530 non-null  bool          \n",
      " 37  Junction               993530 non-null  bool          \n",
      " 38  No_Exit                993530 non-null  bool          \n",
      " 39  Railway                993530 non-null  bool          \n",
      " 40  Roundabout             993530 non-null  bool          \n",
      " 41  Station                993530 non-null  bool          \n",
      " 42  Stop                   993530 non-null  bool          \n",
      " 43  Traffic_Calming        993530 non-null  bool          \n",
      " 44  Traffic_Signal         993530 non-null  bool          \n",
      " 45  Turning_Loop           993530 non-null  bool          \n",
      " 46  Sunrise_Sunset         993519 non-null  object        \n",
      " 47  Civil_Twilight         993519 non-null  object        \n",
      " 48  Nautical_Twilight      993519 non-null  object        \n",
      " 49  Astronomical_Twilight  993519 non-null  object        \n",
      " 50  Year                   993530 non-null  int64         \n",
      " 51  Month                  993530 non-null  object        \n",
      " 52  Day                    993530 non-null  int64         \n",
      " 53  Hour                   993530 non-null  int64         \n",
      " 54  Weekday                993530 non-null  object        \n",
      " 55  Time_Duration(min)     993530 non-null  float64       \n",
      "dtypes: bool(13), datetime64[ns](2), float64(15), int64(5), object(21)\n",
      "memory usage: 338.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"US_accidents_for_5_states.csv\")\n",
    "df['Start_Time'] = pd.to_datetime(df['Start_Time'], errors='coerce')\n",
    "df['End_Time'] = pd.to_datetime(df['End_Time'], errors='coerce')\n",
    "\n",
    "# Extract year, month, day, hour and weekday\n",
    "df['Year']=df['Start_Time'].dt.year\n",
    "df['Month']=df['Start_Time'].dt.strftime('%b')\n",
    "df['Day']=df['Start_Time'].dt.day\n",
    "df['Hour']=df['Start_Time'].dt.hour\n",
    "df['Weekday']=df['Start_Time'].dt.strftime('%a')\n",
    "\n",
    "# Extract the amount of time in the unit of minutes for each accident, round to the nearest integer\n",
    "td='Time_Duration(min)'\n",
    "df[td]=round((df['End_Time']-df['Start_Time'])/np.timedelta64(1,'m'))\n",
    "df.info()\n",
    "\n",
    "\n",
    "dd=df.copy()\n",
    "\n",
    "\n",
    "dd=dd[dd['State']=='KY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop the columns that have a more than half NULL values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22553\n",
      "56\n",
      "(22553, 53)\n"
     ]
    }
   ],
   "source": [
    "print(len(dd))\n",
    "\n",
    "print(len(dd.columns))\n",
    "cols = dd.columns[dd.isnull().mean()>0.5]\n",
    "dd.drop(cols, axis=1,inplace=True)\n",
    "\n",
    "print(dd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22553, 47)\n",
      "Unnamed: 0                0\n",
      "ID                        0\n",
      "Source                    0\n",
      "Severity                  0\n",
      "Start_Time                0\n",
      "End_Time                  0\n",
      "Start_Lat                 0\n",
      "Start_Lng                 0\n",
      "Distance(mi)              0\n",
      "Description               0\n",
      "Street                    0\n",
      "Side                      0\n",
      "City                      0\n",
      "County                    0\n",
      "State                     0\n",
      "Zipcode                   0\n",
      "Country                   0\n",
      "Timezone                  0\n",
      "Airport_Code              0\n",
      "Temperature(F)          114\n",
      "Wind_Chill(F)          9782\n",
      "Humidity(%)             128\n",
      "Pressure(in)            100\n",
      "Visibility(mi)          125\n",
      "Wind_Direction          136\n",
      "Wind_Speed(mph)        1953\n",
      "Precipitation(in)     10516\n",
      "Weather_Condition       122\n",
      "Amenity                   0\n",
      "Bump                      0\n",
      "Crossing                  0\n",
      "Give_Way                  0\n",
      "Junction                  0\n",
      "No_Exit                   0\n",
      "Railway                   0\n",
      "Roundabout                0\n",
      "Station                   0\n",
      "Stop                      0\n",
      "Traffic_Calming           0\n",
      "Traffic_Signal            0\n",
      "Sunrise_Sunset            0\n",
      "Year                      0\n",
      "Month                     0\n",
      "Day                       0\n",
      "Hour                      0\n",
      "Weekday                   0\n",
      "Time_Duration(min)        0\n",
      "dtype: int64\n",
      "22553\n"
     ]
    }
   ],
   "source": [
    "unwanted_cols=['Turning_Loop','Civil_Twilight','Nautical_Twilight','Astronomical_Twilight','Weather_Timestamp','TMC']\n",
    "dd.drop(unwanted_cols, axis=1,inplace=True)\n",
    "\n",
    "print(dd.shape)\n",
    "print(dd.isnull().sum())\n",
    "print(len(dd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                0\n",
      "ID                        0\n",
      "Source                    0\n",
      "Severity                  0\n",
      "Start_Time                0\n",
      "End_Time                  0\n",
      "Start_Lat                 0\n",
      "Start_Lng                 0\n",
      "Distance(mi)              0\n",
      "Description               0\n",
      "Street                    0\n",
      "Side                      0\n",
      "City                      0\n",
      "County                    0\n",
      "State                     0\n",
      "Zipcode                   0\n",
      "Country                   0\n",
      "Timezone                  0\n",
      "Airport_Code              0\n",
      "Temperature(F)          114\n",
      "Wind_Chill(F)          9782\n",
      "Humidity(%)             128\n",
      "Pressure(in)            100\n",
      "Visibility(mi)          125\n",
      "Wind_Direction          136\n",
      "Wind_Speed(mph)        1953\n",
      "Precipitation(in)     10516\n",
      "Weather_Condition       122\n",
      "Amenity                   0\n",
      "Bump                      0\n",
      "Crossing                  0\n",
      "Give_Way                  0\n",
      "Junction                  0\n",
      "No_Exit                   0\n",
      "Railway                   0\n",
      "Roundabout                0\n",
      "Station                   0\n",
      "Stop                      0\n",
      "Traffic_Calming           0\n",
      "Traffic_Signal            0\n",
      "Sunrise_Sunset            0\n",
      "Year                      0\n",
      "Month                     0\n",
      "Day                       0\n",
      "Hour                      0\n",
      "Weekday                   0\n",
      "Time_Duration(min)        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dd.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n",
      "58.45944115156626 60.1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Filling the temperature column missing values with its mean\n",
    "dd_temperature=dd[\"Temperature(F)\"]\n",
    "#approximately follows normal distribution\n",
    "print(dd[\"Temperature(F)\"].isnull().sum())\n",
    "#filling the missing values with the median\n",
    "median_temperature=dd_temperature.median()\n",
    "mean_temperature=dd_temperature.mean()\n",
    "print(mean_temperature,median_temperature)\n",
    "\n",
    "#filling the median temperature into the missing values since we are keeping the outliers\n",
    "dd[\"Temperature(F)\"].fillna(median_temperature, inplace=True)\n",
    "#ensuring that there are no more null values in temperature\n",
    "print(dd['Temperature(F)'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "69.93502787068005 73.0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Filling the humidity column missing values with its mean\n",
    "dd_humidity=dd[\"Humidity(%)\"]\n",
    "\n",
    "#approximately follows normal distribution\n",
    "print(dd[\"Humidity(%)\"].isnull().sum())\n",
    "#filling the missing values with the mean\n",
    "median_humidity=dd_humidity.median()\n",
    "mean_humidity=dd_humidity.mean()\n",
    "print(mean_humidity,median_humidity)\n",
    "#calculating the median and mean humidity and it is left-skewed ditribution\n",
    "\n",
    "#filling the median temperature into the missing values since we are keeping the outliers\n",
    "dd[\"Humidity(%)\"].fillna(mean_humidity, inplace=True)\n",
    "#ensuring that there are no more null values in temperature\n",
    "print(dd['Humidity(%)'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "29.783977196811236 29.91\n",
      "29.783977196811236 29.91\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Filling the Pressure column missing values with its mean\n",
    "dd_Pressure=dd[\"Pressure(in)\"]\n",
    "\n",
    "#approximately follows normal distribution\n",
    "print(dd[\"Pressure(in)\"].isnull().sum())\n",
    "#filling the missing values with the concept of flooring and capping\n",
    "median_Pressure=dd_Pressure.median()\n",
    "mean_Pressure=dd_Pressure.mean()\n",
    "print(mean_Pressure,median_Pressure)\n",
    "\n",
    "new_median_Pressure=dd_Pressure.median()\n",
    "new_mean_Pressure=dd_Pressure.mean()\n",
    "print(new_mean_Pressure,new_median_Pressure)\n",
    "dd[\"Pressure(in)\"].fillna(new_median_Pressure, inplace=True)\n",
    "#ensuring that there are no more null values in pressure\n",
    "print(dd['Pressure(in)'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n",
      "8.803699393615124 10.0\n",
      "8.803699393615124 10.0\n",
      "0\n",
      "Unnamed: 0                0\n",
      "ID                        0\n",
      "Source                    0\n",
      "Severity                  0\n",
      "Start_Time                0\n",
      "End_Time                  0\n",
      "Start_Lat                 0\n",
      "Start_Lng                 0\n",
      "Distance(mi)              0\n",
      "Description               0\n",
      "Street                    0\n",
      "Side                      0\n",
      "City                      0\n",
      "County                    0\n",
      "State                     0\n",
      "Zipcode                   0\n",
      "Country                   0\n",
      "Timezone                  0\n",
      "Airport_Code              0\n",
      "Temperature(F)            0\n",
      "Wind_Chill(F)          9782\n",
      "Humidity(%)               0\n",
      "Pressure(in)              0\n",
      "Visibility(mi)            0\n",
      "Wind_Direction          136\n",
      "Wind_Speed(mph)        1953\n",
      "Precipitation(in)     10516\n",
      "Weather_Condition       122\n",
      "Amenity                   0\n",
      "Bump                      0\n",
      "Crossing                  0\n",
      "Give_Way                  0\n",
      "Junction                  0\n",
      "No_Exit                   0\n",
      "Railway                   0\n",
      "Roundabout                0\n",
      "Station                   0\n",
      "Stop                      0\n",
      "Traffic_Calming           0\n",
      "Traffic_Signal            0\n",
      "Sunrise_Sunset            0\n",
      "Year                      0\n",
      "Month                     0\n",
      "Day                       0\n",
      "Hour                      0\n",
      "Weekday                   0\n",
      "Time_Duration(min)        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Filling the Visibility column missing values with its mean\n",
    "dd_Visibility=dd[\"Visibility(mi)\"]\n",
    "\n",
    "#approximately follows normal distribution\n",
    "print(dd[\"Visibility(mi)\"].isnull().sum())\n",
    "#filling the missing values with the concept of flooring and capping\n",
    "median_Visibility=dd_Visibility.median()\n",
    "mean_Visibility=dd_Visibility.mean()\n",
    "print(mean_Visibility,median_Visibility)\n",
    "\n",
    "new_median_Visibility=dd_Visibility.median()\n",
    "new_mean_Visibility=dd_Visibility.mean()\n",
    "print(new_mean_Visibility,new_median_Visibility)\n",
    "dd[\"Visibility(mi)\"].fillna(new_median_Visibility, inplace=True)\n",
    "#ensuring that there are no more null values in visibility\n",
    "print(dd['Visibility(mi)'].isnull().sum())\n",
    "\n",
    "print(dd.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8149940758927152\n"
     ]
    }
   ],
   "source": [
    "#using the concept of flooring and capping\n",
    "quartile_10=dd['Wind_Speed(mph)'].quantile(0.10) #0\n",
    "quartile_90=dd['Wind_Speed(mph)'].quantile(0.90) #13.8\n",
    "print(dd['Wind_Speed(mph)'].skew())  #38.513"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1953\n",
      "8.340451456310856 8.0\n",
      "8.340451456310856 8.0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Filling the Visibility column missing values with its mean\n",
    "dd_Windspeed=dd[\"Wind_Speed(mph)\"]\n",
    "\n",
    "#approximately follows normal distribution\n",
    "print(dd[\"Wind_Speed(mph)\"].isnull().sum())\n",
    "#filling the missing values with the concept of flooring and capping\n",
    "median_Windspeed=dd_Windspeed.median()\n",
    "mean_Windspeed=dd_Windspeed.mean()\n",
    "print(mean_Windspeed,median_Windspeed)\n",
    "\n",
    "#new mean and median\n",
    "\n",
    "new_median_Windspeed=dd_Windspeed.median()\n",
    "new_mean_Windspeed=dd_Windspeed.mean()\n",
    "print(new_mean_Windspeed,new_median_Windspeed)\n",
    "dd[\"Wind_Speed(mph)\"].fillna(new_median_Windspeed, inplace=True)\n",
    "#ensuring that there are no more null values in visibility\n",
    "print(dd['Wind_Speed(mph)'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSW\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Wind_Direction\n",
    "\n",
    "#filling the category with the mode \n",
    "mode_found=(dd['Wind_Direction'].mode())\n",
    "print(mode_found[0])\n",
    "dd[\"Wind_Direction\"].fillna(mode_found[0], inplace=True)\n",
    "print(dd['Wind_Direction'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                0\n",
      "ID                        0\n",
      "Source                    0\n",
      "Severity                  0\n",
      "Start_Time                0\n",
      "End_Time                  0\n",
      "Start_Lat                 0\n",
      "Start_Lng                 0\n",
      "Distance(mi)              0\n",
      "Description               0\n",
      "Street                    0\n",
      "Side                      0\n",
      "City                      0\n",
      "County                    0\n",
      "State                     0\n",
      "Zipcode                   0\n",
      "Country                   0\n",
      "Timezone                  0\n",
      "Airport_Code              0\n",
      "Temperature(F)            0\n",
      "Wind_Chill(F)          9782\n",
      "Humidity(%)               0\n",
      "Pressure(in)              0\n",
      "Visibility(mi)            0\n",
      "Wind_Direction            0\n",
      "Wind_Speed(mph)           0\n",
      "Precipitation(in)     10516\n",
      "Weather_Condition       122\n",
      "Amenity                   0\n",
      "Bump                      0\n",
      "Crossing                  0\n",
      "Give_Way                  0\n",
      "Junction                  0\n",
      "No_Exit                   0\n",
      "Railway                   0\n",
      "Roundabout                0\n",
      "Station                   0\n",
      "Stop                      0\n",
      "Traffic_Calming           0\n",
      "Traffic_Signal            0\n",
      "Sunrise_Sunset            0\n",
      "Year                      0\n",
      "Month                     0\n",
      "Day                       0\n",
      "Hour                      0\n",
      "Weekday                   0\n",
      "Time_Duration(min)        0\n",
      "dtype: int64\n",
      "Clear\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(dd.isnull().sum())\n",
    "\n",
    "\n",
    "\n",
    "#Weather_Condition\n",
    "#filling the category with the mode \n",
    "mode_found=(dd['Weather_Condition'].mode())\n",
    "print(mode_found[0])\n",
    "dd[\"Weather_Condition\"].fillna(mode_found[0], inplace=True)\n",
    "print(dd['Weather_Condition'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Louisville\n",
      "0\n",
      "Day\n",
      "0\n",
      "Unnamed: 0            0.0\n",
      "ID                    0.0\n",
      "Source                0.0\n",
      "Severity              0.0\n",
      "Start_Time            0.0\n",
      "End_Time              0.0\n",
      "Start_Lat             0.0\n",
      "Start_Lng             0.0\n",
      "Distance(mi)          0.0\n",
      "Description           0.0\n",
      "Street                0.0\n",
      "Side                  0.0\n",
      "City                  0.0\n",
      "County                0.0\n",
      "State                 0.0\n",
      "Country               0.0\n",
      "Temperature(F)        0.0\n",
      "Humidity(%)           0.0\n",
      "Pressure(in)          0.0\n",
      "Visibility(mi)        0.0\n",
      "Wind_Direction        0.0\n",
      "Wind_Speed(mph)       0.0\n",
      "Weather_Condition     0.0\n",
      "Amenity               0.0\n",
      "Bump                  0.0\n",
      "Crossing              0.0\n",
      "Give_Way              0.0\n",
      "Junction              0.0\n",
      "No_Exit               0.0\n",
      "Railway               0.0\n",
      "Roundabout            0.0\n",
      "Station               0.0\n",
      "Stop                  0.0\n",
      "Traffic_Calming       0.0\n",
      "Traffic_Signal        0.0\n",
      "Sunrise_Sunset        0.0\n",
      "Year                  0.0\n",
      "Month                 0.0\n",
      "Day                   0.0\n",
      "Hour                  0.0\n",
      "Weekday               0.0\n",
      "Time_Duration(min)    0.0\n",
      "dtype: float64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 22553 entries, 120455 to 993295\n",
      "Data columns (total 42 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   Unnamed: 0          22553 non-null  int64         \n",
      " 1   ID                  22553 non-null  object        \n",
      " 2   Source              22553 non-null  object        \n",
      " 3   Severity            22553 non-null  int64         \n",
      " 4   Start_Time          22553 non-null  datetime64[ns]\n",
      " 5   End_Time            22553 non-null  datetime64[ns]\n",
      " 6   Start_Lat           22553 non-null  float64       \n",
      " 7   Start_Lng           22553 non-null  float64       \n",
      " 8   Distance(mi)        22553 non-null  float64       \n",
      " 9   Description         22553 non-null  object        \n",
      " 10  Street              22553 non-null  object        \n",
      " 11  Side                22553 non-null  object        \n",
      " 12  City                22553 non-null  object        \n",
      " 13  County              22553 non-null  object        \n",
      " 14  State               22553 non-null  object        \n",
      " 15  Country             22553 non-null  object        \n",
      " 16  Temperature(F)      22553 non-null  float64       \n",
      " 17  Humidity(%)         22553 non-null  float64       \n",
      " 18  Pressure(in)        22553 non-null  float64       \n",
      " 19  Visibility(mi)      22553 non-null  float64       \n",
      " 20  Wind_Direction      22553 non-null  object        \n",
      " 21  Wind_Speed(mph)     22553 non-null  float64       \n",
      " 22  Weather_Condition   22553 non-null  object        \n",
      " 23  Amenity             22553 non-null  bool          \n",
      " 24  Bump                22553 non-null  bool          \n",
      " 25  Crossing            22553 non-null  bool          \n",
      " 26  Give_Way            22553 non-null  bool          \n",
      " 27  Junction            22553 non-null  bool          \n",
      " 28  No_Exit             22553 non-null  bool          \n",
      " 29  Railway             22553 non-null  bool          \n",
      " 30  Roundabout          22553 non-null  bool          \n",
      " 31  Station             22553 non-null  bool          \n",
      " 32  Stop                22553 non-null  bool          \n",
      " 33  Traffic_Calming     22553 non-null  bool          \n",
      " 34  Traffic_Signal      22553 non-null  bool          \n",
      " 35  Sunrise_Sunset      22553 non-null  object        \n",
      " 36  Year                22553 non-null  int64         \n",
      " 37  Month               22553 non-null  object        \n",
      " 38  Day                 22553 non-null  int64         \n",
      " 39  Hour                22553 non-null  int64         \n",
      " 40  Weekday             22553 non-null  object        \n",
      " 41  Time_Duration(min)  22553 non-null  float64       \n",
      "dtypes: bool(12), datetime64[ns](2), float64(9), int64(5), object(14)\n",
      "memory usage: 5.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#City\n",
    "#filling the category with the mode \n",
    "mode_found=(dd['City'].mode())\n",
    "print(mode_found[0])\n",
    "dd[\"City\"].fillna(mode_found[0], inplace=True)\n",
    "print(dd['City'].isnull().sum())\n",
    "\n",
    "#Sunrise_sunset\n",
    "#filling the category with the mode \n",
    "mode_found=(dd['Sunrise_Sunset'].mode())\n",
    "print(mode_found[0])\n",
    "dd[\"Sunrise_Sunset\"].fillna(mode_found[0], inplace=True)\n",
    "print(dd['Sunrise_Sunset'].isnull().sum())\n",
    "#dropping the cols 'Zipcode','Timezone','Airport_Code' \n",
    "unwanted_cols_2=['Zipcode','Timezone','Airport_Code','Wind_Chill(F)','Precipitation(in)']\n",
    "dd.drop(unwanted_cols_2, axis=1,inplace=True)\n",
    "\n",
    "print(dd.isnull().mean())\n",
    "print(dd.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22553, 34)\n"
     ]
    }
   ],
   "source": [
    "# #correlation plots for numerical features\n",
    "# numerical_features=['Start_Lat','Start_Lng','Temperature(F)','Humidity(%)','Pressure(in)','Visibility(mi)','Wind_Speed(mph)']\n",
    "# df_numerical=dd[numerical_features].copy()\n",
    "# print(df_numerical.shape)\n",
    "# sns.heatmap(df_numerical.corr(), annot = True)\n",
    "# print(df_numerical.corr())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#removing the unwanted columns\n",
    "filtered_columns=['Start_Time','End_Time','Description','Street','State','Country','Unnamed: 0','ID']\n",
    "dd.drop(filtered_columns, axis=1,inplace=True)\n",
    "print(dd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing a standardisation on numerical columns such that mean is 0 and variance is 1\n",
    "# numerical features\n",
    "num_cols = ['Temperature(F)','Humidity(%)','Pressure(in)','Visibility(mi)','Wind_Speed(mph)','Distance(mi)']\n",
    "# apply standardization on numerical features\n",
    "for i in num_cols:\n",
    "    # fit on training data column\n",
    "    scale = StandardScaler().fit(dd[[i]])\n",
    "    # transform the training data column\n",
    "    dd[i] = scale.transform(dd[[i]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Approach using one hot encoding/pd.get_dummies for few columns\n",
    "#one hot encoding approach\n",
    "\n",
    "\n",
    "\n",
    "#Copying the dataframe into ds\n",
    "ds=dd.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Start_Lat</th>\n",
       "      <th>Start_Lng</th>\n",
       "      <th>Distance(mi)</th>\n",
       "      <th>Side</th>\n",
       "      <th>City</th>\n",
       "      <th>County</th>\n",
       "      <th>Temperature(F)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>...</th>\n",
       "      <th>Stop</th>\n",
       "      <th>Traffic_Calming</th>\n",
       "      <th>Traffic_Signal</th>\n",
       "      <th>Sunrise_Sunset</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Time_Duration(min)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120455</th>\n",
       "      <td>MapQuest</td>\n",
       "      <td>2</td>\n",
       "      <td>38.766727</td>\n",
       "      <td>-84.188011</td>\n",
       "      <td>0.563767</td>\n",
       "      <td>L</td>\n",
       "      <td>Foster</td>\n",
       "      <td>Bracken</td>\n",
       "      <td>0.454244</td>\n",
       "      <td>-0.200616</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>2016</td>\n",
       "      <td>Mar</td>\n",
       "      <td>27</td>\n",
       "      <td>22</td>\n",
       "      <td>Sun</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120456</th>\n",
       "      <td>MapQuest</td>\n",
       "      <td>2</td>\n",
       "      <td>38.502827</td>\n",
       "      <td>-82.775070</td>\n",
       "      <td>-0.299735</td>\n",
       "      <td>R</td>\n",
       "      <td>Greenup</td>\n",
       "      <td>Greenup</td>\n",
       "      <td>0.850255</td>\n",
       "      <td>-0.965348</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>2016</td>\n",
       "      <td>May</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>Tue</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120457</th>\n",
       "      <td>MapQuest</td>\n",
       "      <td>1</td>\n",
       "      <td>38.534069</td>\n",
       "      <td>-82.834595</td>\n",
       "      <td>-0.307805</td>\n",
       "      <td>R</td>\n",
       "      <td>Greenup</td>\n",
       "      <td>Greenup</td>\n",
       "      <td>0.130235</td>\n",
       "      <td>1.175901</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>2016</td>\n",
       "      <td>May</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>Wed</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152408</th>\n",
       "      <td>MapQuest</td>\n",
       "      <td>2</td>\n",
       "      <td>38.453114</td>\n",
       "      <td>-82.673744</td>\n",
       "      <td>-0.299735</td>\n",
       "      <td>L</td>\n",
       "      <td>Ashland</td>\n",
       "      <td>Boyd</td>\n",
       "      <td>0.027374</td>\n",
       "      <td>0.666080</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Day</td>\n",
       "      <td>2017</td>\n",
       "      <td>Feb</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>Wed</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152409</th>\n",
       "      <td>MapQuest</td>\n",
       "      <td>2</td>\n",
       "      <td>38.453114</td>\n",
       "      <td>-82.673744</td>\n",
       "      <td>-0.299735</td>\n",
       "      <td>L</td>\n",
       "      <td>Ashland</td>\n",
       "      <td>Boyd</td>\n",
       "      <td>-0.132059</td>\n",
       "      <td>1.022955</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Night</td>\n",
       "      <td>2017</td>\n",
       "      <td>Feb</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>Wed</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993229</th>\n",
       "      <td>Bing</td>\n",
       "      <td>4</td>\n",
       "      <td>38.222800</td>\n",
       "      <td>-85.510840</td>\n",
       "      <td>-0.016474</td>\n",
       "      <td>R</td>\n",
       "      <td>Louisville</td>\n",
       "      <td>Jefferson</td>\n",
       "      <td>1.210265</td>\n",
       "      <td>0.054295</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>2019</td>\n",
       "      <td>Aug</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>Tue</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993230</th>\n",
       "      <td>Bing</td>\n",
       "      <td>2</td>\n",
       "      <td>38.222726</td>\n",
       "      <td>-85.515250</td>\n",
       "      <td>0.087630</td>\n",
       "      <td>R</td>\n",
       "      <td>Louisville</td>\n",
       "      <td>Jefferson</td>\n",
       "      <td>1.210265</td>\n",
       "      <td>0.054295</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>2019</td>\n",
       "      <td>Aug</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>Tue</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993289</th>\n",
       "      <td>Bing</td>\n",
       "      <td>2</td>\n",
       "      <td>38.021666</td>\n",
       "      <td>-84.492849</td>\n",
       "      <td>-0.173034</td>\n",
       "      <td>R</td>\n",
       "      <td>Lexington</td>\n",
       "      <td>Fayette</td>\n",
       "      <td>1.518846</td>\n",
       "      <td>-0.863384</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Day</td>\n",
       "      <td>2019</td>\n",
       "      <td>Aug</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>Wed</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993290</th>\n",
       "      <td>Bing</td>\n",
       "      <td>4</td>\n",
       "      <td>38.028528</td>\n",
       "      <td>-84.314463</td>\n",
       "      <td>0.518575</td>\n",
       "      <td>R</td>\n",
       "      <td>Lexington</td>\n",
       "      <td>Fayette</td>\n",
       "      <td>0.901685</td>\n",
       "      <td>0.615098</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>2019</td>\n",
       "      <td>Aug</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>Thu</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993295</th>\n",
       "      <td>Bing</td>\n",
       "      <td>4</td>\n",
       "      <td>38.277260</td>\n",
       "      <td>-85.805890</td>\n",
       "      <td>-0.061667</td>\n",
       "      <td>R</td>\n",
       "      <td>Louisville</td>\n",
       "      <td>Jefferson</td>\n",
       "      <td>1.210265</td>\n",
       "      <td>0.207241</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>2019</td>\n",
       "      <td>Aug</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>Thu</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22553 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Source  Severity  Start_Lat  Start_Lng  Distance(mi) Side  \\\n",
       "120455  MapQuest         2  38.766727 -84.188011      0.563767    L   \n",
       "120456  MapQuest         2  38.502827 -82.775070     -0.299735    R   \n",
       "120457  MapQuest         1  38.534069 -82.834595     -0.307805    R   \n",
       "152408  MapQuest         2  38.453114 -82.673744     -0.299735    L   \n",
       "152409  MapQuest         2  38.453114 -82.673744     -0.299735    L   \n",
       "...          ...       ...        ...        ...           ...  ...   \n",
       "993229      Bing         4  38.222800 -85.510840     -0.016474    R   \n",
       "993230      Bing         2  38.222726 -85.515250      0.087630    R   \n",
       "993289      Bing         2  38.021666 -84.492849     -0.173034    R   \n",
       "993290      Bing         4  38.028528 -84.314463      0.518575    R   \n",
       "993295      Bing         4  38.277260 -85.805890     -0.061667    R   \n",
       "\n",
       "              City     County  Temperature(F)  Humidity(%)  ...   Stop  \\\n",
       "120455      Foster    Bracken        0.454244    -0.200616  ...  False   \n",
       "120456     Greenup    Greenup        0.850255    -0.965348  ...  False   \n",
       "120457     Greenup    Greenup        0.130235     1.175901  ...  False   \n",
       "152408     Ashland       Boyd        0.027374     0.666080  ...  False   \n",
       "152409     Ashland       Boyd       -0.132059     1.022955  ...  False   \n",
       "...            ...        ...             ...          ...  ...    ...   \n",
       "993229  Louisville  Jefferson        1.210265     0.054295  ...  False   \n",
       "993230  Louisville  Jefferson        1.210265     0.054295  ...  False   \n",
       "993289   Lexington    Fayette        1.518846    -0.863384  ...  False   \n",
       "993290   Lexington    Fayette        0.901685     0.615098  ...  False   \n",
       "993295  Louisville  Jefferson        1.210265     0.207241  ...  False   \n",
       "\n",
       "        Traffic_Calming Traffic_Signal  Sunrise_Sunset  Year  Month  Day  \\\n",
       "120455            False          False           Night  2016    Mar   27   \n",
       "120456            False          False             Day  2016    May   10   \n",
       "120457            False          False             Day  2016    May   11   \n",
       "152408            False           True             Day  2017    Feb   22   \n",
       "152409            False           True           Night  2017    Feb   22   \n",
       "...                 ...            ...             ...   ...    ...  ...   \n",
       "993229            False          False             Day  2019    Aug   20   \n",
       "993230            False          False             Day  2019    Aug   20   \n",
       "993289            False           True             Day  2019    Aug   21   \n",
       "993290            False          False           Night  2019    Aug   22   \n",
       "993295            False          False           Night  2019    Aug   22   \n",
       "\n",
       "        Hour  Weekday  Time_Duration(min)  \n",
       "120455    22      Sun                75.0  \n",
       "120456    14      Tue                45.0  \n",
       "120457     8      Wed                90.0  \n",
       "152408    17      Wed                30.0  \n",
       "152409    19      Wed                30.0  \n",
       "...      ...      ...                 ...  \n",
       "993229     9      Tue                29.0  \n",
       "993230     9      Tue                28.0  \n",
       "993289    20      Wed                30.0  \n",
       "993290     1      Thu                29.0  \n",
       "993295     0      Thu                30.0  \n",
       "\n",
       "[22553 rows x 34 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using pd_getdummies i.e one hot encoding\n",
    "features_converted=['Side','Bump','Crossing','Give_Way','Junction','No_Exit','Railway','Roundabout','Station','Stop','Traffic_Calming','Traffic_Signal','Sunrise_Sunset','Year','Month','Day','Hour','Weekday']\n",
    "for i in features_converted:\n",
    "    \n",
    "    ds = pd.concat([ds,pd.get_dummies(ds[i], prefix=i)],axis=1)\n",
    "    ds.drop([i],axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#using label encoding to the rest of the columns having object datatype\n",
    "features_label_encoding=['Source','City','County','Wind_Direction','Weather_Condition']\n",
    "labelencoder = LabelEncoder()\n",
    "# Assigning numerical values and storing in another column\n",
    "\n",
    "for i in features_label_encoding:\n",
    "    ds[i] = labelencoder.fit_transform(ds[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-6f8e429d95c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Split the data set into training and testing data sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "target='Severity'\n",
    "# Create arrays for the features and the response variable\n",
    "# set X and y\n",
    "y = ds[target]\n",
    "X = ds.drop(target, axis=1)\n",
    "\n",
    "# Split the data set into training and testing data sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21, stratify=y)\n",
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred=lr.predict(X_test)\n",
    "\n",
    "# Get the accuracy score\n",
    "acc=accuracy_score(y_test, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using PCA\n",
    "from sklearn.decomposition import PCA\n",
    "# put none to n_componenets to create explained variance vector \n",
    "# ( contain the percentage of variance explained by each of the principal components that we extracted here.)\n",
    "pca = PCA(n_components=2) \n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "expained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "#Fitting logistic Regression to the training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train_pca, y_train)\n",
    "\n",
    "#Prdicting the test set results\n",
    "y_pred = classifier.predict(X_test_pca)\n",
    "acc=accuracy_score(y_test, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Approach using labelencoding for all few columns\n",
    "#labelencoding approach\n",
    "\n",
    "\n",
    "\n",
    "#Copying the dataframe into dr\n",
    "\n",
    "dr=dd.copy()\n",
    "features_label_encoding=['Source','Side','City','County','Wind_Direction','Weather_Condition','Bump','Crossing','Give_Way','Junction','No_Exit','Railway','Roundabout','Station','Stop','Traffic_Calming','Traffic_Signal','Sunrise_Sunset','Year','Month','Day','Hour','Weekday']\n",
    "labelencoder = LabelEncoder()\n",
    "# Assigning numerical values and storing in another column\n",
    "\n",
    "for i in features_label_encoding:\n",
    "    dr[i] = labelencoder.fit_transform(dr[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target='Severity'\n",
    "# Create arrays for the features and the response variable\n",
    "# set X and y\n",
    "y = dr[target]\n",
    "X = dr.drop(target, axis=1)\n",
    "# Split the data set into training and testing data sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21, stratify=y)\n",
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred=lr.predict(X_test)\n",
    "# Get the accuracy score\n",
    "acc=accuracy_score(y_test, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using PCA\n",
    "from sklearn.decomposition import PCA\n",
    "# put none to n_componenets to create explained variance vector \n",
    "# ( contain the percentage of variance explained by each of the principal components that we extracted here.)\n",
    "pca = PCA(n_components=2) \n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "expained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "#Fitting logistic Regression to the training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train_pca, y_train)\n",
    "\n",
    "#Prdicting the test set results\n",
    "y_pred = classifier.predict(X_test_pca)\n",
    "acc=accuracy_score(y_test, y_pred)\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
